{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ratings_graph import RatingsGraph\n",
    "import random\n",
    "#from true_ratings_prediction import debias_ratings_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Biased "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_biased_dataset(num_users, num_entities,gen_entity_features): #gen_user_biases\n",
    "    # The true ratings of the entities\n",
    "    ground_truth_ratings = np.random.random(num_entities)\n",
    "    \n",
    "    # The number of features that define a movie\n",
    "    num_features = 1\n",
    "    \n",
    "    # Each user has a bias value along a certain feature dimension\n",
    "    user_biases = np.zeros((num_users, num_features))\n",
    "    for user_idx in range(num_users):\n",
    "        for feature_idx in range(num_features):\n",
    "            #user_biases[user_idx][feature_idx] = np.random.uniform(-1, 1)\n",
    "            if random.randint(0, 1):\n",
    "                user_biases[user_idx][feature_idx] = 0.1\n",
    "            else:\n",
    "                user_biases[user_idx][feature_idx] = -0.5\n",
    "    \n",
    "    # Setting the features for each entity along each feature dimension\n",
    "    entity_features = np.zeros((num_entities, num_features))\n",
    "    for entity_idx in range(num_entities):\n",
    "        # Currently saying the maximum magnitude of the entity features is 1.0 / num_features\n",
    "        #entity_features[entity_idx, :] = np.random.uniform(0, 1.0/num_features, num_features)\n",
    "        entity_features[entity_idx, :] = gen_entity_features(num_features)\n",
    "    \n",
    "    # TODO: Think about how to intelligently normalize these features\n",
    "    '''\n",
    "    #linfnorm = np.linalg.norm(entity_features, axis=1, ord=2)\n",
    "    #entity_features = entity_features.astype(np.float) / linfnorm[:,None]    \n",
    "    '''\n",
    "    \n",
    "    # Setting the user_item ratings and the user_item adjacency matrix\n",
    "    p_rate = 1\n",
    "    user_entity_ratings = np.zeros((num_users, num_entities))\n",
    "    user_entity_adj_matrix = np.zeros((num_users, num_entities))\n",
    "    for user_idx in range(num_users):\n",
    "        for entity_idx in range(num_entities):\n",
    "            if np.random.random() < p_rate:\n",
    "                user_entity_ratings[user_idx][entity_idx] = ground_truth_ratings[entity_idx] + \\\n",
    "                                                    (np.dot(entity_features[entity_idx, :], user_biases[user_idx,:]))\n",
    "                user_entity_ratings[user_idx][entity_idx] = max(min(user_entity_ratings[user_idx][entity_idx], 1), 0)\n",
    "                \n",
    "                user_entity_adj_matrix[user_idx][entity_idx] = 1\n",
    "\n",
    "    return user_entity_ratings, ground_truth_ratings, user_entity_adj_matrix, entity_features, user_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "EPSILON = 0.000001\n",
    "\n",
    "def single_iteration(ratings_graph, biases, true_ratings, alpha, beta):\n",
    "    # Update Ratings\n",
    "    graph_shape = ratings_graph.get_graph_shape()\n",
    "    indiv_true_ratings = np.maximum(np.zeros(graph_shape), np.minimum(np.ones(graph_shape),\n",
    "                                        ratings_graph.get_user_entity_ratings() - alpha * biases[:, None]))\n",
    "    rating_denoms = ratings_graph.get_entity_rating_counts()\n",
    "    next_true_ratings = np.sum(ratings_graph.get_user_entity_adj_matrix() * indiv_true_ratings, axis=0) / rating_denoms\n",
    "\n",
    "    # Update Biases\n",
    "    indiv_biases = ratings_graph.get_user_entity_ratings() - next_true_ratings\n",
    "    bias_denoms = ratings_graph.get_user_rating_counts()\n",
    "    next_biases = (1-beta)*biases + beta*(np.sum(ratings_graph.get_user_entity_adj_matrix() * indiv_biases, axis=1) / bias_denoms)\n",
    "\n",
    "    converged = True\n",
    "    if ((true_ratings is not None) and np.any(np.abs(true_ratings - next_true_ratings) > EPSILON)) or \\\n",
    "        np.any(np.abs(biases - next_biases) > EPSILON):\n",
    "        converged = False\n",
    "\n",
    "    return converged, next_true_ratings, next_biases\n",
    "\n",
    "def single_iteration_user_ent(ratings_graph, biases, true_ratings, alpha, beta):\n",
    "    # Update Rating\n",
    "    graph_shape = ratings_graph.get_graph_shape()\n",
    "    indiv_true_ratings = np.maximum(np.zeros(graph_shape), np.minimum(np.ones(graph_shape),\n",
    "                                        ratings_graph.get_user_entity_ratings() - alpha * biases))\n",
    "    rating_denoms = ratings_graph.get_entity_rating_counts()\n",
    "    next_true_ratings = np.sum(ratings_graph.get_user_entity_adj_matrix() * indiv_true_ratings, axis=0) / rating_denoms\n",
    "\n",
    "    # Update Biases\n",
    "    indiv_biases = (ratings_graph.get_user_entity_adj_matrix()*(ratings_graph.get_user_entity_ratings() - next_true_ratings)).dot(ratings_graph.get_entity_sim())\n",
    "    bias_denoms = (ratings_graph.get_user_entity_adj_matrix()).dot(ratings_graph.get_entity_sim())\n",
    "    next_biases = (1-beta)*biases + beta*(indiv_biases) / bias_denoms\n",
    "\n",
    "    converged = True\n",
    "    if ((true_ratings is not None) and np.any(np.abs(true_ratings - next_true_ratings) > EPSILON)) or \\\n",
    "        np.any(np.abs(biases - next_biases) > EPSILON):\n",
    "        converged = False\n",
    "\n",
    "    return converged, next_true_ratings, next_biases\n",
    "\n",
    "\n",
    "def mishra_prediction(ratings_graph, initial_alpha=0.99, \\\n",
    "                                     decay_rate=1.00, \\\n",
    "                                     max_iters = 200000, \\\n",
    "                                     beta = 0.1, \\\n",
    "                                     user_entity_specific=False):\n",
    "    np.random.seed(10)\n",
    "    ground_truth_ratings = ratings_graph.get_ground_truth_ratings()\n",
    "    true_ratings = [np.random.uniform((ratings_graph.num_entities,))]\n",
    "    if not user_entity_specific:\n",
    "        biases = [np.random.uniform(low = -1, high = 1, size = (ratings_graph.num_users,))]\n",
    "    else:\n",
    "        biases = [np.random.uniform(low = -1, high = 1, size = (ratings_graph.num_users, ratings_graph.num_entities))]\n",
    "    errors = []\n",
    "\n",
    "    converged = False\n",
    "    num_iters = 0\n",
    "    alpha = initial_alpha\n",
    "    while not converged and num_iters < max_iters:\n",
    "        true_rate_or_none = None if not true_ratings else true_ratings[-1]\n",
    "        if not user_entity_specific:\n",
    "            iter_out = single_iteration(ratings_graph, biases[-1], true_rate_or_none, alpha, beta)\n",
    "        else:\n",
    "            iter_out = single_iteration_user_ent(ratings_graph, biases[-1], true_rate_or_none, alpha, beta)\n",
    "\n",
    "        converged, next_true_ratings, next_biases = iter_out\n",
    "        true_ratings.append(next_true_ratings)\n",
    "        biases.append(next_biases)\n",
    "        if ground_truth_ratings is not None:\n",
    "            errors.append(np.sqrt(np.mean((next_true_ratings - ground_truth_ratings)**2)))\n",
    "        num_iters += 1\n",
    "        alpha = alpha/decay_rate\n",
    "\n",
    "    return biases, true_ratings, errors\n",
    "def mean_prediction(ratings_graph):\n",
    "    user_entity_ratings = ratings_graph.get_user_entity_ratings()\n",
    "    user_entity_adj_matrix = ratings_graph.get_user_entity_adj_matrix()\n",
    "    user_entity_adj_matrix_na = user_entity_adj_matrix.copy()\n",
    "    user_entity_adj_matrix_na[user_entity_adj_matrix==0]=np.nan\n",
    "\n",
    "    mean_pred = np.nanmean(user_entity_ratings*(user_entity_adj_matrix_na), axis=0)\n",
    "    return mean_pred\n",
    "                  \n",
    "def median_prediction(ratings_graph):\n",
    "    user_entity_ratings = ratings_graph.get_user_entity_ratings()\n",
    "    user_entity_adj_matrix = ratings_graph.get_user_entity_adj_matrix()\n",
    "    user_entity_adj_matrix_na = user_entity_adj_matrix.copy()\n",
    "    user_entity_adj_matrix_na[user_entity_adj_matrix==0]=np.nan\n",
    "    \n",
    "    median_pred = np.nanmedian(user_entity_ratings*(user_entity_adj_matrix_na), axis=0)\n",
    "    return median_pred\n",
    "\n",
    "def get_pred_error(pred, ratings_graph):\n",
    "    error = np.sqrt(np.mean((pred - ratings_graph.get_ground_truth_ratings())**2))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_constant_entity_features = lambda num_features: np.ones(num_features)\n",
    "gen_random_entity_features = lambda num_features: np.random.uniform(0, 1.0/num_features, num_features)\n",
    "user_entity_ratings, ground_truth_ratings, user_entity_adj_matrix, entity_features, user_biases = generate_biased_dataset(5, 2000, gen_constant_entity_features)\n",
    "ratings_graph = RatingsGraph(user_entity_ratings, user_entity_adj_matrix, ground_truth_ratings, entity_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error:  0.038265623293592774\n",
      "Median error:  0.09666338604742315\n",
      "Mishra error:  0.038323511825768763\n"
     ]
    }
   ],
   "source": [
    "mean_pred = mean_prediction(ratings_graph)\n",
    "median_pred = median_prediction(ratings_graph)\n",
    "biases, true_ratings, errors = mishra_prediction(ratings_graph)\n",
    "mishra_pred = true_ratings[-1]\n",
    "#print (mean_pred)\n",
    "#print (median_pred)\n",
    "#print (mishra_pred)\n",
    "print ('Mean error: ', get_pred_error(mean_pred, ratings_graph))\n",
    "print ('Median error: ', get_pred_error(median_pred, ratings_graph))\n",
    "print ('Mishra error: ', get_pred_error(mishra_pred, ratings_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.32937063 -0.32937063  0.13740498  0.13740498  0.13740498]\n",
      "[0.19806286 0.76053071 0.16911084 ... 0.18522301 0.36744679 0.69001506]\n"
     ]
    }
   ],
   "source": [
    "print (biases[-1])\n",
    "print(ground_truth_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5]\n",
      " [-0.5]\n",
      " [ 0.1]\n",
      " [ 0.1]\n",
      " [ 0.1]]\n",
      "[0.22765092 0.66934391 0.2102797  ... 0.219947   0.32928127 0.59882826]\n"
     ]
    }
   ],
   "source": [
    "print (user_biases)\n",
    "print (mishra_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_entity_ratings:  [[0.29806286 0.86053071 0.26911084 ... 0.28522301 0.46744679 0.79001506]\n",
      " [0.29806286 0.86053071 0.26911084 ... 0.28522301 0.46744679 0.79001506]\n",
      " [0.         0.26053071 0.         ... 0.         0.         0.19001506]\n",
      " [0.29806286 0.86053071 0.26911084 ... 0.28522301 0.46744679 0.79001506]\n",
      " [0.29806286 0.86053071 0.26911084 ... 0.28522301 0.46744679 0.79001506]]\n",
      "ground_truth_ratings:  [0.19806286 0.76053071 0.16911084 ... 0.18522301 0.36744679 0.69001506]\n",
      "user_entity_adj_matrix:  [[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "entity_features:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "user_biases:  [[ 0.1]\n",
      " [ 0.1]\n",
      " [-0.5]\n",
      " [ 0.1]\n",
      " [ 0.1]]\n"
     ]
    }
   ],
   "source": [
    "print ('user_entity_ratings: ', user_entity_ratings)\n",
    "print ('ground_truth_ratings: ', ground_truth_ratings)\n",
    "print ('user_entity_adj_matrix: ', user_entity_adj_matrix)\n",
    "print ('entity_features: ', entity_features)\n",
    "print ('user_biases: ', user_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
